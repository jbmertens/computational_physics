{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3: Linear Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "In this homework we will focus on\n",
    "- Avoiding writing loops! Become more familiar with using arrays and the functions that act on them.\n",
    "- Become familiar with array slicing.  This is a very powerful was of easily manipulating data, but does require some practice for it to become natural.\n",
    "- Extend array slicing by slicing based on conditions.\n",
    "- Learn to solve systems of linear equations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always you should add initialization to the top of your notebook. Though not strictly necessary, it is a good habit to include all initialization here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7984a64835266ae2",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoiding Loops\n",
    "\n",
    "Loops in `python`, unfortunately, can be slow and prone to coding errors.  We have already been using a few features of `NumPy` that allow us to avoid writing loops: functions work on arrays of values and array slicing allows us to view an array in many ways without having to create a new array.  We will continue to learn about these features along with a few other ones.  Often we  write loops to perform mathematical operations.  In languages that include vector processing capabilities, provided in `python` through the `NumPy` module, there is almost always a function that can be used to perform the calculation without the need to write such a loop.  The price we pay for this is that we must be able to store all of the information needed for the calculation in arrays.  In other words, the tradeoff is between memory usage and computation speed:  with little memory usage we can write a loop which will be slow, with a lot of memory usage we can perform the calculation \"all at once\" using a built-in function which is often significantly faster than the loop.\n",
    "\n",
    "### Sums\n",
    "\n",
    "As a simple example of this consider a sum of integers, this has a known analytic result:\n",
    "\n",
    "$$ \\sum_{j=1}^N j = \\frac{N(N+1)}{2}. $$\n",
    "\n",
    "We can easily evaluate this sum by constructing an array holding all the integers from $1$ to $N$ (including $N$) and using the `sum` function from NumPy. Show the use of the `sum` function by evaluating this sum for various values of $N$ and verifying it agrees with the analytic result.  Show the result for one case (for example $N=12$).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "attachments": {
    "array_structure.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Data in Arrays\n",
    "\n",
    "In our quest to avoid writing loops we need ways of accessing and changing data in arrays without needing to individually step through each element.  We have seen that many numpy operations and functions act on arrays exactly as we would expect (or hope) they would.  We have also seen that array slicing provides a convenient way of accessing parts of an array.  We will now study this more carefully.\n",
    "\n",
    "### Indexing\n",
    "\n",
    "We have already seen how to index elements in an array.  Array indices in python start at zero, whether this seems strange or the obvious choice depends on how you think about arrays and the programming languages you have used.  If you are familiar with pointers or references, then this is the obvious choice.  Consider the array `a = [0, 0.25, 0.5, 0.75, 1]`.  In Python (and C and related languages) if we construct such an array, for example as `a = np.linspace(0, 1, 5)`, then we can think of `a` as pointing to the beginning of the array.  Thus `a[0]` represents moving the pointer zero elements along the array, `a[1]` as moving the pointer one element along the array, and in general `a[j]` as moving `j` elements along the array.  This is represented in the figure below, where we see that `a[2]` is two steps along the array so it contains the value `0.5`.  This choice is confusing in the sense that `a[2]` is the *third element* in the array, not the second.\n",
    "\n",
    "![array_structure.png](attachment:array_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, this choice makes it easy to understand what it means to step backwards in an array.  In particular `a[-1]` represents stepping one element backwards from the beginning of the array with the extra fact that we *wrap around* the array, so that we end up at the last element in it.  We can then understand what any backwards step, `a[-j]`, means.  For the example above this means that `a[-3]` is the same as `a[2]`.\n",
    "\n",
    "Note that while this way of picturing negative indexing is nice, we should be careful not to push it to far.  An array is not cyclic (it is not periodic).  We *can* walk off the end or beginning of the array.  Thus in the example above, `a[j]` is **not defined** for $j\\ge 5$ or $j<-5$.\n",
    "\n",
    "These ideas extend to two dimensional arrays.  For a two dimensional array, `M`, then `M[i,j]` is the element from *row* `i` and column `j`.  Again, both of these index values start from zero.\n",
    "\n",
    "It is expected that you are comfortable accessing elements of an array.  Feel free to generate arrays and play with pulling out specific elements of them.\n",
    "\n",
    "###     Array Slicing\n",
    "\n",
    "Array slicing is discussed in detail in Sections 2.2 and 3.4 of the *Guide to Numpy* (see the course syllabus for a link).  We will only need basic slicing and will study some simple cases here.\n",
    "\n",
    "#### One Dimension\n",
    "\n",
    "The index we use to access elements of an array need not just be a single number.  The generic structure is `[start:end:step]`.  This will give a view of the array starting at index `start` and proceeding up to, *but not including*, index `end` in steps of `step`.  We can leave out any of the values and use the defaults instead.  The default for `start` is the first index (zero), the default for `end` is the length of the array, and the default for `step` is one.  This means there are many ways to reference the whole array.  Let `a` be a one dimensional array, then all the following are equivalent: `a`, `a[:]`, `a[::]`, `a[0:len(a)]`, `a[0:len(a):]`, `a[0::1]`, and `a[0:len(a):1]`. \n",
    "\n",
    "Array slicing is more than just a convenient way of viewing the data, it also allows us to *change* parts of the array.  Technically, array slicing gives a *view* of the array.  It **does not make a copy**, it really produces a \"smart pointer\" that allows us to examine and modify parts of an array.  This is a very important and powerful feature.  For the small arrays we will work with here it would not matter if we made copies, but if we were working with very large arrays this would be very important.\n",
    "\n",
    "Let `a=np.arange(20)`.  Use array slicing to print every third value of the array, that is, to print `a[0]`, `a[3]`, ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.arange(20)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the array of **integers** `a` from the previous part, modify the array so that all the even elements are multiplied by 2, that is, replace all the even values by their values multiplied by 2.  Print the modified array. (*Note:* Python supports in-place operators such as `+=`, `-=`, `*=`, `/=`, `//=`, and a few others that you may be familiar with from other languages.  It does not, however, support `++` nor `--`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: a is an integer array so we need to store an integer in it.\n",
    "# Thus we need to use integer division, which // does for us.\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Higher Dimensions\n",
    "\n",
    "Array slicing works for higher dimensional arrays also.  Let `M` be a two dimensional array with 6 rows and 4 columns.  Since NumPy arrays are accessed in row major order, the fourth row of the array can be accessed as `M[3,:]` or in shorthand as `M[3]`.  The third column can be accessed as `M[:,2]`.  Notice that to access a row we can use a shortcut but to access a column we must specify something about the rows.  In the example of accessing the third column we are asking for all the rows (represented by the `:`).\n",
    "\n",
    "For `M` a 6 by 4 array as discussed above state the size and the specific elements that will be accessed by `M[::2,::3]`.  For example, this will access `M[0,0]`, what other elements will this access?  How many rows and columns will be accessed? (*Note:* You should think about this first, then feel free to construct an example array and test your ideas.)\n",
    "\n",
    "The resulting array will be 3 by 2 and contain the elements from the original array:\n",
    "- `M[0,0]`, `M[0,3]`,\n",
    "- `M[2,0]`, `M[2,3]`,\n",
    "- `M[4,0]`, `M[4,3]`\n",
    "\n",
    "### Conditional Slicing\n",
    "\n",
    "The simple slicing discussed above is great if we have regularly spaced indices we wish to access.  There are also techniques for selecting elements of an array based on other conditions.  One way of doing this is through the `where` command provided by NumPy (you should look through its documentation).  To become familiar with using it we will consider a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.linspace(0, 1, 20)\n",
    "np.where(a>=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the `where` function returns an array of index values for which the condition specified is true.  Actually, if we look more closely at what is printed we see it really is returning a `tuple` of arrays.  This is done because the `where` function also works for multidimensional arrays and it is returning the index values in a more general format.  (This is discussed in the sections of the *Guide to Numpy* noted above.)  This is \"annoying\" when working with 1 dimensional arrays when we are interested in the index values themselves (as opposed to the values in array `a`).  A couple of common idioms for obtaining the array of index values in the one dimensional case are\n",
    "```\n",
    "ind = np.where(a>=0.5)[0]\n",
    "ind, = np.where(a>=0.5)\n",
    "```\n",
    "Notice the comma in the second expression.\n",
    "\n",
    "Construct an array of 20 random values between 0 and 1 using `np.random.rand`.  Use the `where` command to find all values in this array larger than 0.5.  Replace those values with one minus their value, that is \"fold\" them back to be in the interval $[0,0.5]$.  Print the updated array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous question can also be solved without using the `where` command.  We can instead construct a boolean array showing where the condition is satisfied as seen below. This boolean array can also be used as an index.\n",
    "\n",
    "(*Think about the following cell before you run it.  What do you expect to happen and why? Then run them and make sense of the results for yourself!*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.rand(20)\n",
    "boolind = b>0.5\n",
    "print(b)\n",
    "print(boolind)\n",
    "\n",
    "# Only print the values satisfying our condition: b>0.5\n",
    "print(b[boolind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, multiple conditions can be specified using the logical operator `|` for *or* and `&` for *and*.  In doing so we must be careful about *order of operations*.  It is best to enclose conditions in parentheses.  The conditions can be specified in the same way in the `where` command and they create a boolean array.  Again, it is best to look at some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.linspace(0,1,20)\n",
    "# Print all values smaller than 0.25 or larger than 0.75.\n",
    "# We could do this with the where command or a boolean array,\n",
    "# here I show the use of the where command.\n",
    "ind = np.where((a<0.25)|(a>0.75))\n",
    "print(a[ind])\n",
    "# Print all the values between 0.25 and 0.75, inclusive.\n",
    "# Here I show the use of a boolean array.\n",
    "print(a[(a>=0.25)&(a<=0.75)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a 6 by 4 array of random values using `np.random.rand`.  Print all values in the array less than 0.3 or between 0.5 and 0.8, inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Versus Copy\n",
    "\n",
    "NumPy always tries to return a view of an array when it can, only making a copy when it needs to.  The exact rules for this depend on many details we have not discussed.  For us this means that we must always be careful when assigning arrays, or slices of arrays, to variables; particularly if we then change some elements of the arrays or their slices.  Things may not behave as we expect.  This can lead to many hard to discover bugs, particularly when arrays are passed to functions and those functions change elements in the array they receive.  We expect these changes to be localized to the function, but they are not!\n",
    "\n",
    "If we are going to change elements of an array and we are uncertain if it is also stored and used under another name, it is best to make a copy of the array.  For example\n",
    "```\n",
    "b = a.copy()\n",
    "```\n",
    "will ensure that `b` starts with the same elements as `a`, but is a copy, so changing `b` will not affect `a`.\n",
    "\n",
    "To make this more clear consider the following cell.  Think about what you expect `a`, `b`, `c`, and `d` to contain after this is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "b = a[::2]\n",
    "b += 1\n",
    "c = np.arange(10)\n",
    "d = c[::2].copy()\n",
    "d += 1\n",
    "\n",
    "print(\"a =\", a)\n",
    "print(\"b =\", b)\n",
    "print(\"c =\", c)\n",
    "print(\"d =\", d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both `a` and `c` start with integer values from 0 to 9.  Array `b` starts as a **view** of the even indexed values of `a`, so index values 0, 2, ..., 8.  We then add 1 to `b` which changes all of its values to the odd values 1, 3, ..., 9.  Since `b` is a view of `a`, we **also change `a`**!  This is a side effect we may not have expected.  It is powerful and very useful, but can be surprising if we are not aware of it.\n",
    "\n",
    "For `c` and `d` we perform the same operations except that `d` is a **copy** of the 0, 2, ..., 8 index values of `c`, so `d` is a new array.  Thus when we change `d` we only change it, `c` is unaffected.  Thus `d` has the same values as `b` did (for the same reason as above) but `c` remains unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tridiagonal systems\n",
    "\n",
    "For matrices with certain structures, especially matrices with many zero elements, specialized routines often exist. So while we can solve many systems using `scipy.linalg.solve`, that is not always the most efficient choice.  Here we will consider a matrix $\\mathsf{A}$ which is tridiagonal, a form we can use that to both speed up the solution and to simplify the code.  To begin, we can actually avoid the need to compute and store the entire matrix by storing the information in a much simpler, more efficient manner. To exploit the structure, we will instead use `scipy.linalg.solve_banded`.  Look up its documentation!  We need to understand how to use it - we will be working with a similar matrix in this weeks Lab.\n",
    "\n",
    "The documentation fully describes how to store a trigiaconal matrix in a form that exploits its banded nature.  The function works for an arbitrary banded matrix.  Although the documentation is good, to further help let us write out the example they discuss in a bit more detail.  The example in the documentation is a $6\\times6$ banded matrix that we can write out in its entirety as\n",
    "\n",
    "$$\\mathsf{a} = \\left( \\begin{array}{cccccc}\n",
    "a_{00} & a_{01} & 0 & 0 & 0 & 0 \\\\\n",
    "a_{10} & a_{11} & a_{12} & 0 & 0 & 0 \\\\\n",
    "a_{20} & a_{21} & a_{22} & a_{23} & 0 & 0 \\\\\n",
    "0 & a_{31} & a_{32} & a_{33} & a_{34} & 0 \\\\\n",
    "0 & 0 & a_{42} & a_{43} & a_{44} & a_{45} \\\\\n",
    "0 & 0 & 0 & a_{53} & a_{54} & a_{55}\n",
    "\\end{array} \\right).$$\n",
    "\n",
    "This is converted to the banded version, `ab`, as shown in the documentation.  In `ab` the elements marked by an asterisk (`*`) are not used by the algorithm so may be set to any value.  Finally, the algorithm needs to know the number of \"bands\" below and above the main diagonal.  These are specified by the `tuple` `(l,u)`.  Study the documentation to make sure you understand how this matrix, $\\mathrm{a}$, gets converted to the banded version `ab` and what the values `l` and `u` represent.\n",
    "\n",
    "Below, we will consider a tridiagonal matrix with the following elements,\n",
    "\n",
    "$$ \\mathsf{A} = \\left( \\begin{array}{ccccc}\n",
    "-2r & r & 0 & 0 & 0 \\\\\n",
    "r & -2r & r & 0 & 0 \\\\\n",
    "0 & r & -2r & r & 0 \\\\\n",
    "0 & 0 & r & -2r & r \\\\\n",
    "0 & 0 & 0 & r & -2r \n",
    "\\end{array} \\right)$$\n",
    "\n",
    "This matrix, and matrices with similar forms, often appear when we use finite difference methods to solve differential equations. This matrix is in fact a representation of a discrete Laplacian operator! We will return to this idea in the Lab, where we will solve the Schrodinger equation.\n",
    "For now, construct the banded version of this matrix, `ab` as used by `scipy.linalg.sovle_banded`. Also print the matrix for the case when `r=0.25`.\n",
    "\n",
    "This should be possible using array manipulations as discussed above.  If you find yourself writing a lot of code or using a loop, consider how you might use the array slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, suppose we wish to solve the system $\\mathsf{A} \\vec{x} = \\vec{b}$. Given the vector\n",
    "\n",
    "$$\\vec{b} = (0,0,0,0,-1.5)$$\n",
    "\n",
    "(also below), determine $\\vec{x}$ using  `scipy.linalg.sovle_banded`. Again assume $r=0.25$.\n",
    "As a check, your solution should be $\\vec{x} = (1, 2, 3, 4, 5)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([0.,0.,0.,0.,-1.5])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that our matrix $\\mathsf{A}$ is actually a symmetric tridiagonal matrix.  Exploiting this extra symmetry could be even more efficient in terms of memory use and computational time.  This could be done using the even more specialized function `scipy.linalg.solveh_banded`.  Feel free to look up this function and how to use it, though this will not be required for the problems in the lab, you can use it if you desire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Schrödinger Equation\n",
    "\n",
    "**In the lab this week we will solve the Schrödinger equation in one dimension for two different potentials. You should make sure to read through and complete this part of the homework before class on Friday.**\n",
    "\n",
    "Mathematically, much of quantum mechanics reduces to solving eigenvalue problems.  You may have encountered the time independent Schrödinger equation in a quantum course.  In its shortest form it may be written as $\\hat H \\psi(x)=E\\psi(x)$.  Here $\\hat H$ is the Hamiltonian operator which we will have more to say about, $E$ is the energy of the system, and $\\psi(x)$ is the wave function which encodes the information about the state of the system.  The Hamiltonian is determined from the physics, so given a Hamiltonian, our goal is to solve for the energy and the wave function.\n",
    "\n",
    "When we first study quantum mechanics we typically write the Hamiltonian as a differential operator.  For a single particle in one dimension the nonrelativistic Hamiltonian may be written as\n",
    "\n",
    "$$\\hat H = -\\frac{\\hbar^2}{2m} \\frac{\\mathrm{d}^2}{\\mathrm{d}x^2}+V(x).$$\n",
    "\n",
    "Here $\\hbar=h/2\\pi$ is the reduced Planck constant and $V(x)$ is the potential energy (though we will just refer to it as a potential).  It is convenient to work in units of $\\hbar$ and $m$ meaning that they get absorbed into the energies.  In this case the Schrödinger equation becomes\n",
    "\n",
    "$$ -\\frac12 \\frac{\\mathrm{d}^2 \\psi(x)}{\\mathrm{d}x^2}+V(x)\\psi(x)=E\\psi(x).$$\n",
    "\n",
    "In a quantum mechanics course we solve this equation for various choices of the potential energy.  To solve it numerically we can proceed in a number of ways.  One is to use a differential equation integrator, such as `scipy.integrate.odeint`, to do the work for us.  [Since this is such an important equation, specialized integrators have been developed which would be even better to use.]  *An alternative approach* is to instead we will turn it into a matrix equation and solve it as an eigenvalue problem.\n",
    "\n",
    "We can discretize the second derivative using\n",
    "\n",
    "$$ \\frac{\\mathrm{d}^2 \\psi(x)}{\\mathrm{d}x^2} = \\frac{\\psi(x-h) - 2 \\psi(x) + \\psi(x+h)}{h^2} + \\mathcal{O}(h^2).$$\n",
    "\n",
    "Note that here $h$ is a step size, and is unrelated to Planck's constant.  Despite the fact that this algorithm is only accurate to order $h^2$ it will be sufficient for our purposes.  With this we can rewrite the Schrödinger equation in matrix form\n",
    "\n",
    "$$ \\mathsf{H}\\vec\\psi = E\\vec\\psi, $$\n",
    "\n",
    "where $\\mathsf{H}$ is now *a matrix representing our Hamiltonian* and $\\vec\\psi$ is now *a vector representing our wave function*.\n",
    "\n",
    "### Understanding the Linear System\n",
    "\n",
    "We need to understand the linear system we just wrote down. The approach we will use and the structure we will find is very similar to that above.  To this end it is best to again grab some paper in order to work out some of the details.  We are again solving a one dimensional system in a region of length $L$ along the $x$-axis.  To do so we discretize the wave function by evaluating it at $N+1$ points. Further we will take these points to be equally spaced with step size $h$ along the $x$-axis so that $\\psi_j \\equiv \\psi(x_j)$ with $x_j = x_0 + j h$.  With this and the discretized form of the second derivative we can rewrite $\\hat H \\psi(x)$ in the discrete (matrix) form $\\mathsf{H}\\vec \\psi$.  Use this to find the form of $\\mathsf{H}$.  You should find it is a symmetric tridiagonal matrix.\n",
    "\n",
    "As above, it is best to begin with a small system.  Again let $N=4$ (so that we have 5 points).  Write out the 5 equations, one for each of the components $\\psi_j$, and use this to construct the matrix $\\mathsf{H}$. For the boundary conditions let $\\psi_{-1} = \\psi_{N+1} = 0$.  Notationally it is also convenient to write $V_j\\equiv V(x_j)$. You should arrive at a matrix with the following form\n",
    "\n",
    "$$ \\mathsf{H} = \\left( \\begin{array}{ccccc}\n",
    "\\frac1{h^2}+V_0 & -\\frac1{2h^2} & 0 & 0 & 0 \\\\\n",
    "-\\frac1{2h^2} & \\frac1{h^2}+V_1 & -\\frac1{2h^2} & 0 & 0 \\\\\n",
    "0 & -\\frac1{2h^2} & \\frac1{h^2}+V_2 & -\\frac1{2h^2} & 0 \\\\\n",
    "0 & 0 & -\\frac1{2h^2} & \\frac1{h^2}+V_3 & -\\frac1{2h^2} \\\\\n",
    "0 & 0 & 0 & -\\frac1{2h^2} & \\frac1{h^2}+V_4 \n",
    "\\end{array} \\right)\\,.$$\n",
    "\n",
    "### Eigenvalue Problem\n",
    "\n",
    "Now that we know $\\mathsf{H}$ we can solve the eigenvalue problem $\\mathsf{H}\\vec\\psi = E\\vec\\psi$ for $E$ and $\\psi$.  Since $\\mathsf{H}$ is a tridiagonal matrix it is again best to use a specialized function for this case.  Thus instead of using `scipy.linalg.eig` or `scipy.linalg.eigh` we will use `scipy.linalg.eig_banded`.  Look up its documentation.  You should see it is similar to what we encountered above, except that it requires a symmetric banded matrix.  Fortunately that is exactly what we have.  In fact, this function is more similar to `scipy.linalg.solveh_banded`. \n",
    "\n",
    "It is easiest to use the function in its default configuration.  This means it will return both the eigenvalues and eigenvectors for $\\mathsf{H}$ given the upper part of the matrix.  Once again study the documentation and pay particular attention to the *upper form* in the example.  There they show an example of a $6\\times6$ matrix with 5 \"diagonals\" (2 upper and 2 lower bands along with the main diagonal.)\n",
    "\n",
    "Provide code for constructing the matrix $\\mathsf{H}$ in banded form as used by `scipy.linalg.eig_banded`.  Your code should work for arbitrary $N$, $h$, and potential $V(x)$.  To test your code apply it to the case where $N=4$, use points equally spaced on the interval $[0,1]$, and choose $V(x)=x^2$.  Print the banded matrix you construct.  (Its structure should make sense!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "Unfortunately we are not quite done.  By convention when we solve an eigenvalue problem the eigenvectors are returned as unit vectors.  This means that when we solve the Schrödinger equation as an eigenvalue problem the eigenvectors will satisfy $|\\vec\\psi|^2 = 1$.  However, in quantum mechanics to allow a probabilistic interpretation of the wave function we instead require the integral condition\n",
    "\n",
    "$$ \\int |\\psi(x)|^2 \\mathrm{d}x = 1.  $$\n",
    "\n",
    "(Here the integral is over the entire region where $\\psi(x)\\ne 0$.)  **These are not the same conditions.**  This means we need to renormalize the eigenvector to be consistent with the requirement from quantum mechanics.\n",
    "\n",
    "Given an eigenvector, $\\vec\\psi$, how must we modify it to be consistent with the normalization condition from quantum mechanics?  To determine this it is simplest to discretize the integral condition from quantum mechanics.  Here it is sufficient to use the Riemann sum form of the integral from calculus, with equally spaced points, and see what rescaling is required in order that the integral condition is satisfied.  In other word, solving the eigenvalue problem gives us a vector, let us call it $\\vec\\psi^{(\\mathrm{ev})}$, that satisfies $|\\vec\\psi^{(\\mathrm{ev})}|^2=1$.  The state relevant for quantum mechanics is proportional to this, $\\vec\\psi = \\alpha \\vec\\psi^{(\\mathrm{ev})}$.  Our objective is to find $\\alpha$. \n",
    "\n",
    "Using the Riemann sum (as the simplest example of a numerical integral, other methods will behave the same way) with spacing $h$ between points we have\n",
    "\n",
    "$$ 1 = \\int |\\psi(x)|^2 \\mathrm{d}x \\approx \\sum_j |\\psi(x_j)|^2 h = h \\sum_j |\\alpha\\psi_j^{(\\mathrm{ev})}|^2 = h \\alpha^2 |\\vec \\psi^{(\\mathrm{ev})}|^2 = h \\alpha^2. $$\n",
    "\n",
    "Thus we require\n",
    "$$ \\alpha = \\frac1{\\sqrt h} $$\n",
    "so that\n",
    "$$ \\vec\\psi = \\frac{\\vec\\psi^{(\\mathrm{ev})}}{\\sqrt h}. $$"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "authors": [
   {
    "name": "Craig J Copi",
    "semester": "Spring 2019"
   }
  ],
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
