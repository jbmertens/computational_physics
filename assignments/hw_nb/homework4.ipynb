{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4 : Curve Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "For the most part, this homework is more about learning and less about doing.  It is important to think about and understand what is presented here.  The main objectives of this homework are given below.\n",
    "* Learn another way to avoid writing loops ourselves, even in cases when it looks like we would need to, by using the `np.vectorize()` function.\n",
    "* Explore more carefully the meaning and use of the $\\chi^2$, in particular the roles of the uncertainties.\n",
    "* Learn more about reading data from the web using `urllib.request` along with the `with` statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "As always you should add initialization to the top of your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fe908b01c259689d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function vectorization\n",
    "\n",
    "As we have seen, operating on an array of values is easier and more efficient than writing our own loop to evaluate the values one at a time.  When performing fits to data we must have a function that accepts and evaluates an array of input values.  Unfortunately there are some functions that do not work in this way.  Consider the example of a piecewise function; suppose we wish to evaluate \n",
    "\n",
    "$$ f(a, b) = \\begin{cases} \n",
    "      a-b & a > b \\\\\n",
    "      a+b & a \\le b\n",
    "   \\end{cases}\n",
    "$$ \n",
    "\n",
    "A simple way to implement this is given below.  It suffers from the limitation that we cannot pass arrays, `a` and `b`, to `f`.  In the past we would have written a loop to go through all the values of `x` and compute the function one value at a time.  An alternative approach is to let NumPy vectorize the function for us using `np.vectorize()`.\n",
    "\n",
    "##### Study and Run the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a, b):\n",
    "    \"Return a-b if a>b, otherwise return a+b\"\n",
    "    if a > b:\n",
    "        return a - b\n",
    "    else:\n",
    "        return a + b\n",
    "\n",
    "# With this setup we can verify it works by doing, for example\n",
    "f(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it works for a single value, this is not surprising.  On the other hand, it does not work if we pass in an array.  Instead we get a hard to understand error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.linspace(1, 2, 10)\n",
    "b = np.linspace(3, 4, 10)\n",
    "# This should produce an error.\n",
    "f(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, if we vectorize the code it magically works! There will always be cases where a function will not already be vectorized for us and `np.vectorize()` will be a convenient way to work around this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead we can define a new function F(x) using vectorize():\n",
    "F = np.vectorize(f)\n",
    "# Now ...\n",
    "F(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be noted that `np.vectorize()` is not actually working magic and **does not make your code faster**, it is merely a convenience function that allows you to avoid explicitly writing a loop.  Essentially what it is doing is writing the loop for you.  It loops over your input arrays and executes the function once for each value in the arrays, collects these values, and returns them to you in a new array.  The case encountered here is one example where this is useful, and you may note is the first example in the documentation for `np.vectorize()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding $\\chi^2$\n",
    "\n",
    "We have introduced the $\\chi^2$ and will use it to fit for parameters of a model given some data, but what is it really?  We know that given some data represented by the values $y_i$ and uncertainties $\\sigma_i$ when evaluated at some points $x_i$ we can fit for the parameters, $\\vec p$, of a model $f(x, \\vec p)$.  Even if $f(x, \\vec p)$ is a linear function of the parameters, $\\vec p$, when there are more data points, $\\vec y$, than there are parameters, $\\vec p$, there will **not be a unique solution** for $\\vec p$.  Instead we look for a set of parameters such that the curve described by the model is \"close\" to the data.  Many choices could be made to define what \"close\" means.  The one we make when performing least squares fitting is to minimize $\\chi^2$ defined by\n",
    "\n",
    "$$ \\chi^2 = \\sum_{i=1}^{n} \\left( \\frac{ y_i - f(x_i, \\vec p) }{\\sigma_i} \\right)^2. $$\n",
    "\n",
    "This choice makes some sense, it looks similar to the distance between points in Euclidean space (otherwise known as the Pythagorean theorem).\n",
    "\n",
    "The $\\chi^2$ is useful even without performing a fit.  Since it gives a measure of the \"distance\" between the data and a model, it can be used to quantify how \"good a fit\" the model is to the data.  Unfortunately this *is* the way it is phrased.  We talk about \"goodness of fit\" even when the $\\chi^2$ is not minimized in order to find the best fit parameters.  In other words, $\\chi^2$ can be used to perform model comparisons.  When we speak of the \"goodness of fit\" we mean the probability that the $\\chi^2$ value would exceed the value calculated by chance for the number of degrees.  In statistics this is referred to as a one-sided $p$-value.  We will continue to call it the goodness of fit, but it is perhaps better to think of it as a $p$-value.\n",
    "\n",
    "To get some practice and gain more familiarity with the $\\chi^2$ value we will generate some fake data and analyze it.  You should think about each of the comparisons performed below to develop some intuition of what to look for in plots of data.  Essentially we want to gain some experience in performing \"chi by eye\", this means to get a rough idea of how well a model agrees with the data just by looking at plots.  This is a common thing to do when seeing data presented in talks or a paper!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Random Data\n",
    "\n",
    "To begin, we generate some random data for the simple curve\n",
    "\n",
    "$$ y(x; A, \\phi) = A\\sin(x+\\phi) $$\n",
    "\n",
    "with $A=4$ and $\\phi=0.4$. We first generate random $x$ values in the range $0\\le x<3\\pi$.  With these we calculate the true values from the curve and then  generate random fluctuations to represent observational uncertainties.  Here we use Gaussian noise with a constant uncertainty for all observations $\\sigma_y$.  (This is of course not necessary, it just makes the calculations a little easier.)\n",
    "\n",
    "**Run the following cell.**  We want to use the same data for all our analysis below.  If you rerun this cell you will get new random data and must rerun all your analysis cells so that the results are consistent. (You are encouraged to generate and analyze a number of different sets of random data to see how the results can vary.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random data.  Rerun all subsequent analysis cells after this.\n",
    "A = 4.0\n",
    "phi = 0.4\n",
    "sigma_y = 2\n",
    "x = np.random.rand(30) * 3*np.pi\n",
    "def ymodel(x, A, phi) :\n",
    "    return A*np.sin(x + phi)\n",
    "ytrue = ymodel(x, A, phi)\n",
    "y = ytrue + sigma_y * np.random.randn(len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Model Comparison\n",
    "\n",
    "For our random data we know the values of the parameters $A$ and $\\phi$ from the true model.   We will use this to see what a \"good\" model should look like.\n",
    "\n",
    "The first thing we should do is plot the data and a curve representing the true model.   Make a quick plot using `matplotlib.pyplot.errorbar` to plot both the data and a curve for the model. You should look up the documentation for the `errorbar` plotting function before using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-17d8453852141ebf",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the $\\chi^2$ using the true values for the parameters $A$ and $\\phi$ in the model.  Print the $\\chi^2$, the number of degrees of freedom, and the goodness of fit. (*Hint:* We are **not** performing a fit so how many parameters are we allowing to vary and what does this mean for the number of degrees of freedom?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-be5e248c4b54f8fd",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainties\n",
    "\n",
    "The uncertainty, $\\sigma_y$, plays a very important role in the fit.  It sets the scale for how accurately we know each data point and thus how much weight we should give to each data point.  In every case we have discussed, will encounter, and probably have encountered, we mean that the uncertainty \"has the same units\" as the data and is already \"normalized\" to the data.  It seems that there are other choices.  For example, the [weighted least squares](https://en.wikipedia.org/wiki/Weighted_least_squares) is one generalization.  Unfortunately, it seems this is the choice made as the default in `scipy.optimize.curve_fit`.  This choice means that **we must always use** `absolute_sigma=True`.  If we do not, the uncertainties in our fit parameters will not be reported correctly!\n",
    "\n",
    "Even before we perform a fit, we can explore the role of uncertainties.  We may think it is best to *overestimate* the uncertainty \"just to be safe\".  Recalculate the $\\chi^2$ now using twice the uncertainty, meaning replace $\\sigma_y$ with $2 \\sigma_y$ in your calculation.  Print the $\\chi^2$, the number of degrees of freedom, and the goodness of fit for this case.  Also produce another quick plot of the data and the true model but now with the doubled uncertainty for the error bars on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-23c0986a23c472ef",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the $\\chi^2$, goodness of fit, **and from the plot itself** this result should not look correct. But the goodness of fit should be very, very close to one, why is this a problem?\n",
    "\n",
    "We expect the $\\chi^2$ to roughly equal the number of degrees of freedom.  A goodness of fit too close to one means the model is too good!  We see this from the plot in that the curve goes through (almost) all the error bars.  In practice it should only go through some of them (about 68 percent of them).  This suggests that either the error bars are too large, the uncertainties are not Gaussian distributed, or the data is faked!\n",
    "\n",
    "Alternatively, we might want to \"show off\" how good we are at performing experiments and thus *underestimate* the uncertainties.  We also should also never do this!  Repeat the previous calculation now with $\\sigma_y$ replaced by $\\sigma_y/2$.  Print the $\\chi^2$, the number of degrees of freedom, and the goodness of fit for this case.  Also produce another quick plot of the data and the true model but now with the halved uncertainty for the error bars on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a23bbe8892a429e0",
     "locked": false,
     "points": 0.25,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the $\\chi^2$, goodness of fit, and from the plot itself, we can see that this model also does not agree well with the data. We have the opposite problem now, the $\\chi^2$ is too large, the goodness of fit is too small, and the curve for the model does not pass through most off the error bars.  (Again, the curve should pass through about 68 percent of the error bars.)  All of this means the data is not consistent with the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Fit\n",
    "\n",
    "Finally we *can* minimize the $\\chi^2$ to find the best fit values for the parameters $A$ and $\\phi$. It may come as a surprise to note that the best fit values are **not the true values**, even though we have generated fake data using particular values for the parameters, know the true errors, *etc*.  You should find the $\\chi^2$ is smaller **but the goodness of fit may not be better** when the parameters take on values different than the true ones.  Further, the values of the parameters should be \"close\" to the true values with \"close\" here being defined by the uncertainties in the best fit parameter values.\n",
    "\n",
    "Perform a fit to the model using `scipy.optmize.curve_fit`.  Do not forget to use `absolute_sigma=True`.  Print the best fit values for the parameters $A$ and $\\phi$ along with their uncertainties.  Also print the $\\chi^2$, the number of degrees of freedom, and the goodness of fit for the parameters found from this fit. (*Hint:* Since the parameters are now being fit for, what should the number of degrees of freedom be?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-de753946a0c2cb56",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce a nice figure showing the data with its errors bars.  Include in the figure a curve representing the true model and one representing the best fit model.  (*Note:* It may not be obvious that the best fit model has a small $\\chi^2$, though it is worth staring at your figure to see that it seems plausible.  Depending on your random realization the two curves may or may not be very different.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1dfb330831f20885",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What did we just learn?\n",
    "\n",
    "The calculations performed above are nice, but what do we learn from them?  The answer is somewhat subtle; such is the nature of statistics.  Since we are using random data, some of the small details of the calculations can change.  It is worthwhile to rerun the calculations for a few different data sets to see which results change and which do not.  (If you do this, make sure you leave your notebook in a state where all the calculations have been run for the same set of random data.)  We should find that the $\\chi^2$ and goodness of fit for a model using the true parameters varies, perhaps even significantly.  On the other hand, doubling the error bars always leads to a goodness of fit extremely close to zero and halving the error bars always leads to a very poor goodness of fit.  Finally, the best fit parameters will not be the true values but will always be close (usually within 2 or 3 times the uncertainty in the parameters), the $\\chi^2$ will be smaller than that from the model with the known parameters, but the goodness of fit will sometimes be smaller and sometimes be larger.\n",
    "\n",
    "This last point may seem strange.  How can it be that we have the best fit parameters and yet the goodness of fit be worse?  The important point is that **when we perform a statistical calculation we are answering a specific question**.  We must clearly understand the question we are asking before we can interpret the results.  Further, if we ask a different question we will get a different answer and it is often difficult to know how to compare the results from two different statistical calculations.\n",
    "\n",
    "In the calculations performed here we have asked two different questions.  In the first case we had a fixed model with **no free parameters**.  Here we were asking how close is the data to a particular model with particular values for the parameters.  In the second case we had a model with two parameters which could be optimized to find the values that best reproduce the data (best in the least squares sense).  Here we were asking for the best fit values of the parameters in our model given the data.  The \"fitting\" performed used some of the information in the data points to tune the values of the parameters, thus all of the data points were no longer independent pieces of information.  Since we were asking different questions it is not surprising that trying to compare the values for the goodness of fit between the two cases can be confusing.\n",
    "\n",
    "Turning this around, comparing different cases such as we have here can be used to address the question of whether the data justifies (or needs) a more complicated model.  Do we need to add more parameters to the model and fit for their best values?  If adding more parameters does not worsen the goodness of fit then we are not justified in adding them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data from Text Files\n",
    "\n",
    "Plain text files are a common way of storing data. They have the advantage of being very flexible, readable by anyone (you can directly look at it), and platform independent.  This flexibility comes at a cost: since they need not follow a rigid structure they can be difficult and slow to parse.\n",
    "\n",
    "For simple, well formed text files NumPy provides the `loadtxt` function.  For more general text files we can instead use `genfromtxt`.  We will explore both of these functions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data from the Web\n",
    "\n",
    "We have previously seen that we can directly read data from the web using `urllib` without needing to download the file ourselves. We will similarly need to read a data file for this homework.\n",
    "\n",
    "Given a url in a variable called `url` we can open the file as we saw in a previous assignment using\n",
    "```\n",
    "import urllib.request\n",
    "fp = urllib.request.urlopen(url)\n",
    "```\n",
    "Though this works, it is not the best way to do things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `with` Statement\n",
    "\n",
    "The simple way we described things above is actually bad practice.  What we really should do when we open and read a file is\n",
    "1. Open the file.\n",
    "2. Check/catch any errors.\n",
    "3. Read the data.\n",
    "4. Close the file (that is, clean up after ourselves).\n",
    "\n",
    "In general we do not do this, we just open the file, read it, and forget about it, hoping everything just worked.  Fortunately, there is an idiomatic way to do this more correctly in Python by using the `with` statement.  For our purpose the `with` statement just provides a local definition of some object, allows us to use it in a block of code, then cleans up this object after the block of code is executed.\n",
    "\n",
    "We will use this below.  In our examples we will open the remote file using `urllib`, call this opened file `fp`, and then read it.  Once the code in the `with` block is done executing the object `fp` will no longer exist and cannot be used again.  It will be properly closed for us.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `loadtxt()`\n",
    "\n",
    "There are a number of data sets available for extracting information about the expansion rate of the Universe from type Ia supernova data.  One such source is from [Pan-STARRS](https://archive.stsci.edu/prepds/ps1cosmo/).  Such sources give us detailed data for each supernova which would allow us to model their light curves, apply color corrections to calibrate them, *etc.*  While that would be essential if we were performing a careful scientific analysis of the data, that is not what we want to do here.  We will use a simpler (and a bit older) data set that has done some of the processing for us already.  We will only focus on the cosmology, not on the astrophysics.\n",
    "\n",
    "Thus, the data we will use later comes from the Supernova Cosmology Project (the Union 2.1 set). It is stored in a text file that you may access from its original site at\n",
    "http://supernova.lbl.gov/union/figures/SCPUnion2.1_mu_vs_z.txt .\n",
    "\n",
    "Note that this is an actual data file used in research projects.  See the [Supernova Cosmology Project page](http://supernova.lbl.gov/union/) for more information.  As noted above, we can directly read this data file from the web without having to download it!  To read a text file, `np.loadtxt` is the simplest choice.  It is meant to be used to read simple text files where the same number of data values are given in each line of the file.  This will mostly work in our case.\n",
    "\n",
    "The code below is the general method for doing this.  You should see that it does not quite work, an exception is raised about a conversion error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://supernova.lbl.gov/union/figures/SCPUnion2.1_mu_vs_z.txt\"\n",
    "import urllib.request\n",
    "with urllib.request.urlopen(url) as fp :\n",
    "    X = np.loadtxt(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"problem\" is that the first column contains strings (the names of the supernova).  Unfortunately `np.loadtxt()` assumes that all columns contain numbers.  Fortunately we can get around this by only reading in the columns we need.  In this case we will only use columns two, three, and four.\n",
    "\n",
    "Modify the code above to allow us to read the datafile using `np.loadtxt()`, but only read in columns two, three, and four. Print to result to show that you have actually read in the correct data. (*Hint:* See the documentation for `np.loadtxt()` and pay particular attention to the `usecols` keyword.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9112ca9c596a06bf",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `genfromtxt()`\n",
    "\n",
    "The more general, and thus more complicated, function for reading a text file is `genfromtxt`.  This can handle text files with different numbers of values on each line.  It has many, many options that can be used to read data from files even with crazy formatting choices.  **We do not need to use `genfromtxt()` for our data file.**  Even so, it is worth seeing what it does.  Run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(url) as fp :\n",
    "    data = np.genfromtxt(fp)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that it read in the full file, filling in `nan` for the strings.  Not necessarily ideal, but at least it did read in all the numeric information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For actual work, it would be far better to use Pandas for reading in and processing text or tabular data. In high-performance computing applications, other more efficient file formats are commonly used, including HDF (heirarchical data format) which can be accessed through the [h5py](https://docs.h5py.org/en/stable/) module, FITS files (flexable image transport system), which can be accessed through the [PyFITS](https://pyfits.readthedocs.io/en/latest/) module, and others. Database formats are also accessible through modules such as [MySQL](https://dev.mysql.com/doc/connector-python/en/), [SQLite](https://docs.python.org/3/library/sqlite3.html), and more.\n",
    "These are large, powerful packages that we, unfortunately, will not have time to explore.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expansion Rate of the Universe\n",
    "\n",
    "The 2011 Nobel prize in physics was awarded to Saul Perlmutter, Brian P. Schmidt, and Adam G. Riess \"for the discovery of the accelerating expansion of the Universe through observations of distant supernovae\". Using the data we have just loaded, we can perform our own analysis of a recent compilation of supernova data. As always there will be a few things we need to know before we look at the data.\n",
    "\n",
    "Note that we are working with the real data provided by the observers! If you look at this file you will see it contains five columns. Columns two, three, and four we are interested in:\n",
    " * second column : redshift of the supernova ($z$),\n",
    " * third column : distance modulus ($\\mu$, see below for a discussion of this),\n",
    " * fourth column : uncertainty in the distance modulus.\n",
    "\n",
    "Below is a cell to read the data file and store the redshift, distance modulus, and the uncertainty in the distance modulus in arrays. We will use these arrays below. Here we take advantage of an additional unpack keyword, used to make storing the columns of data slightly easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(url) as fp :\n",
    "    (z, mu, sigmamu) = np.loadtxt(fp, usecols=(1,2,3), unpack=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosmology\n",
    "\n",
    "As we will discover, this data shows that the expansion rate of the Universe is accelerating. To do this we will fit for a couple cosmological parameters. The relevant parameters are $q_0$, the \"acceleration parameter\", and $h$, the reduced Hubble constant. A positive $q_0$ means we live in an accelerating universe, while a negative value indicates a decelerating universe.\n",
    "\n",
    "To discover the acceleration we need to relate these parameters to the observations from the data file. Describing distances in an expanding universe is not as simple as in Euclidean space, so leads to more complicated looking equations. We will leave the details to a cosmology course, for our purposes we need to calculate the distance modulus.\n",
    "\n",
    "The distance modulus, $\\mu$, is a way of measuring the distance to an object in terms of its magnitude. It is given by\n",
    "\n",
    "$$ \\mu(z; h, q_0) = 43.23 - 5 \\log_{10}\\left(\\frac{h}{0.7 z}\\right) + 1.086 (1-q_0) z\\,.$$\n",
    "\n",
    "In the distance modulus the logarithm is base 10, not the natural logarithm. Recall that log returns the natural logarithm.\n",
    "Keeping this in mind, define a function that will allow us to calculate the distance modulus for an array of redshift values. I recommend you define the distance modulus with default arguments as\n",
    "\n",
    "    def distance_modulus(z, h=0.7, q0=0.0) :\n",
    "\n",
    "This will be convenient in what follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit this function for $q_0$ and $h$, using the `z`, `mu`, and `sigmamu` arrays. Print the best fit values, their uncertainties, and  the $\\chi^2$ for the fit, the number of degrees of freedom, and the goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us put our results together into a single figure. Plot the data with error bars using `errorbar`. Include a line for the best fit model. Also include lines for a (relatively) large positive and negative acceleration parameter, with $(h, q_0) = (0.7, 1)$ and $(0.7, -1)$. You should see by eye that these other models do not fit the data well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although not conclusive, the $\\chi^2$ and goodness of fit suggest $q_0 > 0$, so the supernova data require the expansion rate of our Universe to be accelerating. Working with a more complete model than we have used here, but also a much smaller set of supernova data, a similar conclusion was reached in 1998 resulting in a Nobel prize."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "authors": [
   {
    "name": "Craig J Copi",
    "semester": "Spring 2019"
   }
  ],
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
