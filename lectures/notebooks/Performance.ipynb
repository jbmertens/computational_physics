{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Performance.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lP1syePvBbzq",
        "Ey7Hb7Zf-vTe",
        "d0xr8Ay5Y5uy"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNdotlrQzn1l"
      },
      "source": [
        "# Improving code performance in Python "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjjGsCu3rBGq"
      },
      "source": [
        " - Homework: reading, think of ?'s for guest speakers, work on project. Sign up for 1-1 meeting on Monday you want.\n",
        "\n",
        " - Friday: Guest speakers\n",
        "\n",
        " - Monday: project check-in\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP1syePvBbzq"
      },
      "source": [
        "## 1. Parallel Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkQlGLr7Bg_Y"
      },
      "source": [
        "As with many other languages, Python does have some support for running commands in parallel. This type of programming comes in a few flavors, including multi-threading, GPU-based parallelism, and MPI. GPU computing (passing off calculations to graphics cards) can be useful for a variety of tasks, but does require specialized hardware and so we will not pursue that idea here. MPI (message passing interface) parallelism is also useful in a high performance computing setting where computing clusters are involved, so we will also forego this.\n",
        "\n",
        "Parallelism is somewhat less efficient in Python due to the way it has been developed. It contains a 'global interpreter', through which most logic will be executed. Threads in python effectively work around this by starting multiple python processes. This type of structure works well for \"trivially parallelizable\" tasks, but becomes more cumbersome as the complexity of code increases; it isn't too difficult to bump up against the limitations of this approach.\n",
        "\n",
        "Thread-based parallelism is available through a couple modules. Here we will look at functionality contained within [joblib.Parallel](https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_RjOnKMBgeU"
      },
      "source": [
        "from joblib import Parallel, delayed\n",
        "?Parallel"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78Yi21oAVK-2"
      },
      "source": [
        "So, we can call `Parallel`, and supply it with a function to iterate over. We can use one of the `%time` or `%timeit` [magic commands](https://ipython.readthedocs.io/en/stable/interactive/magics.html) to get an idea of how fast execution times are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6P4lLtQVU0K",
        "outputId": "0979a184-c9ad-493a-b8c1-37c70a63b342"
      },
      "source": [
        "import numpy as np\n",
        "from time import sleep\n",
        "\n",
        "# Sleep for 1 second, 6 times.\n",
        "print(\"Sleeping for 6 seconds with one thread...\")\n",
        "%time [sleep(1) for i in range(6)]\n",
        "\n",
        "# 2 threads sleep for a total 6 seconds, so this should take 3 seconds to run.\n",
        "print(\"\\n\\nSleeping for 6 seconds across 2 threads...\")\n",
        "%time Parallel(n_jobs=2)(delayed(sleep)(1) for i in range(6))\n",
        "\n",
        "# 2 threads sleep for a total 6 seconds, so this should take 2 seconds to run?\n",
        "print(\"\\n\\nSleeping for 6 seconds across 3 threads...\")\n",
        "%time Parallel(n_jobs=3)(delayed(sleep)(1) for i in range(6)) # n_jobs = threads"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sleeping for 6 seconds with one thread...\n",
            "CPU times: user 26.9 ms, sys: 3.19 ms, total: 30.1 ms\n",
            "Wall time: 6.01 s\n",
            "\n",
            "\n",
            "Sleeping for 6 seconds across 2 threads...\n",
            "CPU times: user 24.6 ms, sys: 2.05 ms, total: 26.7 ms\n",
            "Wall time: 3.04 s\n",
            "\n",
            "\n",
            "Sleeping for 6 seconds across 3 threads...\n",
            "CPU times: user 22.6 ms, sys: 12.2 ms, total: 34.8 ms\n",
            "Wall time: 2.22 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gPlpfiIeRRA"
      },
      "source": [
        "How many CPUs do we actually have?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uxAJa-6eUHj",
        "outputId": "81e53031-68d3-46b9-b8c8-f503e40dff24"
      },
      "source": [
        "import psutil as ps\n",
        "print(\"# local CPUs is:\", ps.cpu_count())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# local CPUs is: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG9AOdk8WjOm"
      },
      "source": [
        "So multiple threads can run on the same CPU, but not necessarily efficiently.\n",
        "\n",
        "The `Parallel` call returns output of the command as well,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX1d3sbytYbW",
        "outputId": "9ebf4983-a8f2-47bd-e978-6a24e08b52e5"
      },
      "source": [
        "[np.sqrt(i) for i in range(6)]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 1.0, 1.4142135623730951, 1.7320508075688772, 2.0, 2.23606797749979]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JENyCb8TWiTm",
        "outputId": "78c5e670-d93b-4d99-9737-9ebdeefa2d96"
      },
      "source": [
        "Parallel(n_jobs=2)(delayed(np.sqrt)(i) for i in range(6))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 1.0, 1.4142135623730951, 1.7320508075688772, 2.0, 2.23606797749979]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAPR56AiedtJ"
      },
      "source": [
        "Below we try a slightly more complicated example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGSCdFLpXAX9",
        "outputId": "f664d649-0250-4b84-b2ae-45551df1d18c"
      },
      "source": [
        "# As a slightly more complicated example, let's integrate a set of special functions.\n",
        "from scipy.integrate import quad\n",
        "from scipy.special import spherical_jn\n",
        "\n",
        "def bessel_integral(n) :\n",
        "  return quad(lambda z: spherical_jn(n, z)/z, 0, np.inf, limit=10000)\n",
        "\n",
        "# This should take a few seconds.\n",
        "print(\"Running with one thread...\")\n",
        "%time values = [ bessel_integral(i) for i in range(1, 9) ]\n",
        "\n",
        "# We might expect this to take half the time if run on 2 cores.\n",
        "print(\"\\n\\nRunning with 2 threads now...\")\n",
        "%time Parallel(n_jobs=2)(delayed(bessel_integral)(i) for i in range(1, 9))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running with one thread...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
            "  the requested tolerance from being achieved.  The error may be \n",
            "  underestimated.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.25 s, sys: 0 ns, total: 3.25 s\n",
            "Wall time: 3.27 s\n",
            "\n",
            "\n",
            "Running with 2 threads now...\n",
            "CPU times: user 44.5 ms, sys: 1.71 ms, total: 46.2 ms\n",
            "Wall time: 3.08 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.7853982627819827, 5.079640384986206e-07),\n",
              " (0.3333336924982387, 5.888876016268974e-07),\n",
              " (0.19634944168331162, 5.385902947241394e-07),\n",
              " (0.13333298120149809, 5.671209072632966e-07),\n",
              " (0.09817487142158836, 1.2012872389194351e-06),\n",
              " (0.07619081841751907, 5.363645518841054e-07),\n",
              " (0.06135839608844671, 2.875120197823322e-07),\n",
              " (0.05079332019865245, 5.000602467386539e-07)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abQf512kHnTQ"
      },
      "source": [
        "### Quick Exercise\n",
        "\n",
        "Recall the first midterm where we looked at the Eigenvalues of random, symmetric matrices. Suppose we were unsatisfied with the results from the single matrices we considered there, and instead we wanted to look at the distribution of Eigenvalues of many matrices.\n",
        "\n",
        "Below, write a function that generates a $1000\\times1000$ matrix with random elements on the interval (0, 1), symmetrizes it, and returns the Eigenvalues. Recall we can extract the symmetric part of a matrix M as $(M + M^{\\rm T})/2$.\n",
        "\n",
        "Compute the Eigenvalues of 10 of these matrices. Is the calculation significantly faster when using multiple threads?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcSkFHAViA0_",
        "outputId": "93918664-3eb3-4c00-b90b-230b2e4e5728"
      },
      "source": [
        "import scipy.linalg as la\n",
        "\n",
        "def rand_eigvals(n) :\n",
        "  mat = np.random.rand(n, n)\n",
        "  return np.real(la.eigvals(0.5*(mat+mat.T)))\n",
        "\n",
        "print(\"Generating matrices in serial.\")\n",
        "%time evs=[rand_eigvals(1000) for _ in range(10)]\n",
        "\n",
        "print(\"\\n\\nGenerating matrices in parallel.\")\n",
        "evs2 = Parallel(n_jobs=2, verbose=5)(delayed(rand_eigvals)(1000) for _ in range(10))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating matrices in serial.\n",
            "CPU times: user 18.1 s, sys: 8.32 s, total: 26.4 s\n",
            "Wall time: 13.5 s\n",
            "\n",
            "\n",
            "Generating matrices in parallel.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    8.9s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    8.9s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey7Hb7Zf-vTe"
      },
      "source": [
        "## 2. Cython (Numba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0uoXpqU-qWR"
      },
      "source": [
        "We have a few options within Python to further improve and optimize code performance. Python is, unfortunately, not one of the most efficient languages. A quick comparison of algorithms in Python to other languages will show this. The below comparison was of algorithms written naively, using \n",
        "\n",
        "![benchmarks.svg](https://julialang.org/assets/benchmarks/benchmarks.svg)\n",
        "\n",
        "This is, to an extent, not an entirely fair comparison: various Python modules can and will pass function calls to highly efficient code written in e.g. c or fortran. Such is the case with many routines within numpy and scipy that we looked at during the semester.\n",
        "\n",
        "Nevertheless, other languages can take advantage of *compilers* to translate high-level code you may have written to low-level machine code. Modern compilers can heavily optimize code during this process, restructuring it, and even optimizing it so it can run more efficiently on specific hardware.\n",
        "\n",
        "One extension exists that allows you to, essentially, compile Python code, or to mix Python and c code: Cython. We can load the Cython extension in a Jupyter notebook as follows,\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mHVnBuexX6F"
      },
      "source": [
        "%load_ext Cython"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bATNcwQ560FO"
      },
      "source": [
        "If you would like to do this on your own computer, you can install Cython locally. You can also use Cython outside of a notebook environment, but usage will be more complicated.\n",
        "\n",
        "Below is a simple function which performs some basic multiplication."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjXWqGhCyF0r"
      },
      "source": [
        "def test(x):\n",
        "    y = 1\n",
        "    for i in range(1, x+1):\n",
        "        y *= i\n",
        "    return y"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuZ1hPIE_pC0",
        "outputId": "2ea925a5-3927-4098-be50-d0663f0381ca"
      },
      "source": [
        "%timeit -n 2000 test(20)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000 loops, best of 5: 1.58 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSH5ZCZC8Psh"
      },
      "source": [
        "We will need to prefix a Cython cell with the `%%cython` command.\n",
        "Below we do so, similarly defining a cython function that performs the same task. We can add the `-a` option to see what has been optimized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-OSg1tWyGgA"
      },
      "source": [
        "%%cython\n",
        "def test1(x):\n",
        "    y = 1\n",
        "    for i in range(1, x+1):\n",
        "        y *= i\n",
        "    return y"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGjZJRBhyTP9",
        "outputId": "016aef24-81d3-4ef1-b9ed-727656fd1888"
      },
      "source": [
        "%timeit -n 2000 test1(20)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000 loops, best of 5: 947 ns per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti8aUgls_435"
      },
      "source": [
        "That doesn't seem to have helped much.\n",
        "However, within cython, we can also specify variables as types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMui2iqh_VO5"
      },
      "source": [
        "%%cython\n",
        "def test2(int x): # The argument x will be an integer.\n",
        "    cdef int y = 1 # y will be an integer,\n",
        "    cdef int i # i will also be an integer.\n",
        "    for i in range(1, x+1):\n",
        "        y *= i\n",
        "    return y"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr6OYCLJ_llj",
        "outputId": "8cdfaf0a-554b-45f2-88f2-56a4c7289d17"
      },
      "source": [
        "%timeit -n 2000 test2(20)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000 loops, best of 5: 150 ns per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W97YNnTUAz29"
      },
      "source": [
        "### Quick exercise\n",
        "\n",
        "The Fibonacci numbers are defined through the recurrence relation,\n",
        "$$ F_i = F_{i − 1} + F_{i−2}\\,,$$\n",
        "with $F_0 = 0$ and $F_1 = 1$.\n",
        "\n",
        "Below write a function to compute the $n$th Fibonacci number. You can do this using e.g. a loop or a recursive function. You should use floating point numbers instead of integers for this; the Fibonacci numbers grow very quickly.\n",
        "\n",
        "Compute the 100th Fibonacci number, and time how fast your code executes. See if you can compile your function with Cython, and improve its speed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUX-VoWnADsC",
        "outputId": "d23e2688-979a-49fb-fbfa-c318811df735"
      },
      "source": [
        "def python_fib(n):\n",
        "    a = 0.0\n",
        "    b = 1.0\n",
        "    for i in range(n):\n",
        "        tmp = a\n",
        "        a = a + b\n",
        "        b = tmp\n",
        "    return a\n",
        "\n",
        "%timeit -n 200 python_fib(100)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 4.59 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "200 loops, best of 5: 9.35 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU0p5_Z548Fk"
      },
      "source": [
        "%%cython\n",
        "def cython_fib(int n):\n",
        "    cdef double a = 0\n",
        "    cdef double b = 1\n",
        "    cdef double tmp\n",
        "    for i in range(n):\n",
        "        tmp = a\n",
        "        a = a + b\n",
        "        b = tmp\n",
        "    return a"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHVJTNIV4-5E",
        "outputId": "6fe01f93-777d-4008-cea2-afbb1a39da2e"
      },
      "source": [
        "%timeit -n 200 cython_fib(100)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200 loops, best of 5: 261 ns per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6pvQp5nB5vY"
      },
      "source": [
        "### Numba\n",
        "\n",
        "Another option for compiling code is numba. To compile a function, the basic syntax looks something like\n",
        "\n",
        "```\n",
        "from numba import jit\n",
        "compiled_function = jit(uncompiled_function)\n",
        "```\n",
        "\n",
        "where `uncompiled_function` is, appropriately, an uncompiled function. See if you can use numba to compile your function; how does its execution speed compare now?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D90gKdnyBjK-",
        "outputId": "c188ffb9-2591-4495-f011-e7229aa1e47e"
      },
      "source": [
        "from numba import jit\n",
        "jfib = jit(python_fib)\n",
        "%timeit -n 200 jfib(100)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 1834.28 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "200 loops, best of 5: 349 ns per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUKHFckYGsyv"
      },
      "source": [
        "## High-performance I/O"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0xr8Ay5Y5uy"
      },
      "source": [
        "A number of highly efficient file formats exist for storing large amount of data. These include formats such as hdf5, fits, and others; for smaller amounts of data less efficient and structured formats such as csv formats may be useful. Python contains routines to interface with all of these formats and many more.\n",
        "\n",
        "### MySQL\n",
        "\n",
        "For dynamic datasets, where you want to access or modify specific parts of a large amount of data, database systems exist. One example of such a system is MySQL. SQL (\"standard query language\") is a language designed for accessing databases; MySQL is one database system that utilizes this language. Here, we will only look at a few basic commands, but this language is quite powerful, along with extensions (e.g. NoSQL). We will need to install a special package for MySQL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i84g8FGkHsrc"
      },
      "source": [
        "!pip -q install mysql-connector-python"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTIPmZQBKYfx"
      },
      "source": [
        "We can then initialize a connection. Below we connect to `ensembldb.ensembl.org`, a public database that contains a large amount of genomic data. We will need to specify the server, user, and a specific database to connect to. Here we will look at a database with information about troglodytes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEb0iwMhHTKo"
      },
      "source": [
        "import mysql.connector\n",
        "mydb = mysql.connector.connect(\n",
        "  host=\"ensembldb.ensembl.org\",\n",
        "  user=\"anonymous\",\n",
        "  password=\"\",\n",
        "  database=\"pan_troglodytes_core_100_3\"\n",
        ")\n",
        "mycursor = mydb.cursor(mydb)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RiLpgVXMSoX"
      },
      "source": [
        "We can view tables of data within this database by running an appropriate command, `SHOW TABLES`. We could similarly see other databases, `SHOW DATABASES`, but we will just look at troglodytes for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM42Wvz-Hkvy",
        "outputId": "79cbd586-fdfe-4c45-f458-ab78aef37ff5"
      },
      "source": [
        "mycursor.execute(\"SHOW TABLES\")\n",
        "for x in mycursor:\n",
        "  print(x)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('alt_allele',)\n",
            "('alt_allele_attrib',)\n",
            "('alt_allele_group',)\n",
            "('analysis',)\n",
            "('analysis_description',)\n",
            "('assembly',)\n",
            "('assembly_exception',)\n",
            "('associated_group',)\n",
            "('associated_xref',)\n",
            "('attrib_type',)\n",
            "('biotype',)\n",
            "('coord_system',)\n",
            "('data_file',)\n",
            "('density_feature',)\n",
            "('density_type',)\n",
            "('dependent_xref',)\n",
            "('ditag',)\n",
            "('ditag_feature',)\n",
            "('dna',)\n",
            "('dna_align_feature',)\n",
            "('dna_align_feature_attrib',)\n",
            "('exon',)\n",
            "('exon_transcript',)\n",
            "('external_db',)\n",
            "('external_synonym',)\n",
            "('gene',)\n",
            "('gene_archive',)\n",
            "('gene_attrib',)\n",
            "('genome_statistics',)\n",
            "('identity_xref',)\n",
            "('interpro',)\n",
            "('intron_supporting_evidence',)\n",
            "('karyotype',)\n",
            "('map',)\n",
            "('mapping_session',)\n",
            "('mapping_set',)\n",
            "('marker',)\n",
            "('marker_feature',)\n",
            "('marker_map_location',)\n",
            "('marker_synonym',)\n",
            "('meta',)\n",
            "('meta_coord',)\n",
            "('misc_attrib',)\n",
            "('misc_feature',)\n",
            "('misc_feature_misc_set',)\n",
            "('misc_set',)\n",
            "('object_xref',)\n",
            "('ontology_xref',)\n",
            "('operon',)\n",
            "('operon_transcript',)\n",
            "('operon_transcript_gene',)\n",
            "('peptide_archive',)\n",
            "('prediction_exon',)\n",
            "('prediction_transcript',)\n",
            "('protein_align_feature',)\n",
            "('protein_feature',)\n",
            "('repeat_consensus',)\n",
            "('repeat_feature',)\n",
            "('rnaproduct',)\n",
            "('rnaproduct_attrib',)\n",
            "('rnaproduct_type',)\n",
            "('seq_region',)\n",
            "('seq_region_attrib',)\n",
            "('seq_region_mapping',)\n",
            "('seq_region_synonym',)\n",
            "('simple_feature',)\n",
            "('stable_id_event',)\n",
            "('supporting_feature',)\n",
            "('transcript',)\n",
            "('transcript_attrib',)\n",
            "('transcript_intron_supporting_evidence',)\n",
            "('transcript_supporting_feature',)\n",
            "('translation',)\n",
            "('translation_attrib',)\n",
            "('unmapped_object',)\n",
            "('unmapped_reason',)\n",
            "('xref',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4JFmrDNMvgZ"
      },
      "source": [
        "We can obtain more information about a specific table using the `DESCRIBE` command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXBfPg58LiAx",
        "outputId": "4fe0f1e3-ca73-40e4-d168-48a3ea2267fc"
      },
      "source": [
        "mycursor.execute(\"DESCRIBE gene\")\n",
        "for x in mycursor:\n",
        "  print(x)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('gene_id', 'int(10) unsigned', 'NO', 'PRI', None, 'auto_increment')\n",
            "('biotype', 'varchar(40)', 'NO', '', None, '')\n",
            "('analysis_id', 'smallint(5) unsigned', 'NO', 'MUL', None, '')\n",
            "('seq_region_id', 'int(10) unsigned', 'NO', 'MUL', None, '')\n",
            "('seq_region_start', 'int(10) unsigned', 'NO', '', None, '')\n",
            "('seq_region_end', 'int(10) unsigned', 'NO', '', None, '')\n",
            "('seq_region_strand', 'tinyint(2)', 'NO', '', None, '')\n",
            "('display_xref_id', 'int(10) unsigned', 'YES', 'MUL', None, '')\n",
            "('source', 'varchar(40)', 'NO', '', None, '')\n",
            "('description', 'text', 'YES', '', None, '')\n",
            "('is_current', 'tinyint(1)', 'NO', '', '1', '')\n",
            "('canonical_transcript_id', 'int(10) unsigned', 'NO', 'MUL', None, '')\n",
            "('stable_id', 'varchar(128)', 'YES', 'MUL', None, '')\n",
            "('version', 'smallint(5) unsigned', 'YES', '', None, '')\n",
            "('created_date', 'datetime', 'YES', '', None, '')\n",
            "('modified_date', 'datetime', 'YES', '', None, '')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdWaUumjPI15",
        "outputId": "b337660a-7c45-42fd-8b56-f789e40fc854"
      },
      "source": [
        "mycursor.execute(\"SELECT * FROM gene LIMIT 10\")\n",
        "for x in mycursor:\n",
        "  print(x)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 'Mt_tRNA', 1, 120533, 1, 71, 1, None, 'RefSeq', None, 1, 1, 'ENSPTRG00000042638', 1, datetime.datetime(2012, 11, 8, 14, 22, 14), datetime.datetime(2012, 11, 8, 14, 22, 14))\n",
            "(2, 'Mt_rRNA', 1, 120533, 72, 1020, 1, None, 'RefSeq', None, 1, 2, 'ENSPTRG00000042646', 1, datetime.datetime(2012, 11, 8, 14, 22, 14), datetime.datetime(2012, 11, 8, 14, 22, 14))\n",
            "(3, 'Mt_tRNA', 1, 120533, 1021, 1089, 1, None, 'RefSeq', None, 1, 3, 'ENSPTRG00000042654', 1, datetime.datetime(2012, 11, 8, 14, 22, 14), datetime.datetime(2012, 11, 8, 14, 22, 14))\n",
            "(4, 'Mt_rRNA', 1, 120533, 1090, 2647, 1, None, 'RefSeq', None, 1, 4, 'ENSPTRG00000042645', 1, datetime.datetime(2012, 11, 8, 14, 22, 14), datetime.datetime(2012, 11, 8, 14, 22, 14))\n",
            "(5, 'Mt_tRNA', 1, 120533, 2648, 2722, 1, None, 'RefSeq', None, 1, 5, 'ENSPTRG00000042644', 1, datetime.datetime(2012, 11, 8, 14, 22, 14), datetime.datetime(2012, 11, 8, 14, 22, 14))\n",
            "(6, 'protein_coding', 1, 120533, 2725, 3681, 1, 10317784, 'RefSeq', 'mitochondrially encoded NADH:ubiquinone oxidoreductase core subunit 1 [Source:VGNC Symbol;Acc:VGNC:11717]', 1, 6, 'ENSPTRG00000042641', 1, datetime.datetime(2012, 11, 8, 14, 22, 14), datetime.datetime(2012, 11, 8, 14, 22, 14))\n",
            "(7, 'Mt_tRNA', 1, 120533, 3681, 3749, 1, None, 'RefSeq', None, 1, 7, 'ENSPTRG00000042627', 1, datetime.datetime(2012, 11, 8, 14, 22, 14), datetime.datetime(2012, 11, 8, 14, 22, 14))\n",
            "(8, 'Mt_tRNA', 1, 120533, 3747, 3818, -1, None, 'RefSeq', None, 1, 8, 'ENSPTRG00000042647', 1, datetime.datetime(2012, 11, 8, 14, 22, 14), datetime.datetime(2012, 11, 8, 14, 22, 14))\n",
            "(9, 'Mt_tRNA', 1, 120533, 3820, 3887, 1, None, 'RefSeq', None, 1, 9, 'ENSPTRG00000042652', 1, datetime.datetime(2012, 11, 8, 14, 22, 14), datetime.datetime(2012, 11, 8, 14, 22, 14))\n",
            "(10, 'protein_coding', 1, 120533, 3888, 4931, 1, 10317787, 'RefSeq', 'mitochondrially encoded NADH:ubiquinone oxidoreductase core subunit 2 [Source:VGNC Symbol;Acc:VGNC:11719]', 1, 10, 'ENSPTRG00000042626', 1, datetime.datetime(2012, 11, 8, 14, 22, 14), datetime.datetime(2012, 11, 8, 14, 22, 14))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX_3RH6dSlTr"
      },
      "source": [
        "### Filesystem I/O\n",
        "\n",
        "We can also compare performance of reading and writing to a few file formats. Here we compare some core Python functionality, with numpy, with the HDF5 format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFdaOugNR7gQ",
        "outputId": "f30d3d88-f5a3-4500-c9a1-ed9e878f425d"
      },
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "randmat = np.random.rand(1000, 1000)\n",
        "\n",
        "print(\"Time taken to save binary data using native python...\")\n",
        "file = open(\"standard.bin\", \"wb\")\n",
        "%time file.write(randmat)\n",
        "file.close()\n",
        "\n",
        "print(\"\\nTime taken to save ascii data...\")\n",
        "%time np.savetxt(\"ascii.npz\", randmat)\n",
        "\n",
        "print(\"\\nTime taken to save numpy data...\")\n",
        "%time np.savez(\"numpy.npz\", randmat)\n",
        "\n",
        "print(\"\\nTime taken to save compressed numpy data...\")\n",
        "%time np.savez_compressed(\"compressed.npz\", randmat)\n",
        "\n",
        "print(\"\\nTime taken to save HDF5 data...\")\n",
        "f = h5py.File(\"h5file.h5\", \"w\")\n",
        "%time dset = f.create_dataset(\"mydataset\", data=randmat)\n",
        "f.close()\n",
        "\n",
        "print(\"\\nTime taken to save compressed HDF5 data...\")\n",
        "f = h5py.File(\"h5compressed.h5\", \"w\")\n",
        "%time dset = f.create_dataset(\"mydataset\", data=randmat, compression=\"gzip\", compression_opts=9)\n",
        "f.close()\n",
        "\n",
        "print(\"\\n\")\n",
        "! ls -lath"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken to save binary data using native python...\n",
            "CPU times: user 383 µs, sys: 5.16 ms, total: 5.54 ms\n",
            "Wall time: 5.55 ms\n",
            "\n",
            "Time taken to save ascii data...\n",
            "CPU times: user 1.03 s, sys: 39.6 ms, total: 1.07 s\n",
            "Wall time: 1.08 s\n",
            "\n",
            "Time taken to save numpy data...\n",
            "CPU times: user 10.5 ms, sys: 9.04 ms, total: 19.6 ms\n",
            "Wall time: 19.7 ms\n",
            "\n",
            "Time taken to save compressed numpy data...\n",
            "CPU times: user 460 ms, sys: 11.9 ms, total: 472 ms\n",
            "Wall time: 476 ms\n",
            "\n",
            "Time taken to save HDF5 data...\n",
            "CPU times: user 880 µs, sys: 6.08 ms, total: 6.96 ms\n",
            "Wall time: 6.91 ms\n",
            "\n",
            "Time taken to save compressed HDF5 data...\n",
            "CPU times: user 247 ms, sys: 9.84 ms, total: 257 ms\n",
            "Wall time: 256 ms\n",
            "\n",
            "\n",
            "total 62M\n",
            "-rw-r--r-- 1 root root 7.3M Apr 26 20:48 h5compressed.h5\n",
            "-rw-r--r-- 1 root root 7.7M Apr 26 20:48 h5file.h5\n",
            "-rw-r--r-- 1 root root 7.2M Apr 26 20:48 compressed.npz\n",
            "-rw-r--r-- 1 root root 7.7M Apr 26 20:48 numpy.npz\n",
            "-rw-r--r-- 1 root root  24M Apr 26 20:48 ascii.npz\n",
            "-rw-r--r-- 1 root root 7.7M Apr 26 20:48 standard.bin\n",
            "drwxr-xr-x 1 root root 4.0K Apr 26 18:11 .\n",
            "drwxr-xr-x 1 root root 4.0K Apr 26 15:27 ..\n",
            "drwxr-xr-x 4 root root 4.0K Apr 21 13:38 .config\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}